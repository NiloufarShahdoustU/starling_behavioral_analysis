{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d88a4d6-96e0-4f0b-b75e-d2b236148054",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import seaborn as sns \n",
    "from matplotlib.ticker import MaxNLocator\n",
    "from matplotlib.ticker import FixedLocator\n",
    "import statsmodels.api as sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d7de5fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_path = 'data'\n",
    "dataframes = []\n",
    "\n",
    "\n",
    "for file_name in os.listdir(folder_path):\n",
    "    if file_name.endswith('.xlsx'):\n",
    "        file_path = os.path.join(folder_path, file_name)\n",
    "        df = pd.read_excel(file_path)\n",
    "        \n",
    "        # Calculate mean and standard deviation of spaceRT\n",
    "        # Calculate 3*std for spaceRT and add as a new column we do this for knowing the spaceRT outliers and remove them in\n",
    "        # calculating spaceRT cause these are rest somehow \n",
    "        # the spaceRT_2sd is obviously same in all columns cause it's based on all the spaceRTs. I just wanted to have everything\n",
    "        # in the dataframe\n",
    "        mean_spaceRT = df['spaceRT'].mean()\n",
    "        std_spaceRT = df['spaceRT'].std()\n",
    "        df['spaceRT_2sd'] = mean_spaceRT + 2 * std_spaceRT\n",
    "        \n",
    "\n",
    "        dataframes.append(df)\n",
    "\n",
    "dataframes[5].head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c524ae4",
   "metadata": {},
   "outputs": [],
   "source": [
    "for df in dataframes:\n",
    "    df['block_type'] = None\n",
    "\n",
    "    df.loc[df['block'] == 1, 'block_type'] = 'uniform'     # Block 1 is uni\n",
    "    df.loc[df['block'] == 4, 'block_type'] = 'mix'     # Block 4 is mix\n",
    "\n",
    "    # For blocks 2 and 3, set based on distribution\n",
    "    df.loc[(df['block'] == 2) & (df['distribution'] == 'low'), 'block_type'] = 'low'\n",
    "    df.loc[(df['block'] == 2) & (df['distribution'] == 'high'), 'block_type'] = 'high'\n",
    "    df.loc[(df['block'] == 3) & (df['distribution'] == 'low'), 'block_type'] = 'low'\n",
    "    df.loc[(df['block'] == 3) & (df['distribution'] == 'high'), 'block_type'] = 'high'\n",
    "    \n",
    "dataframes[0].head(3)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7ab58e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1) Define the risk dictionaries for each deck type\n",
    "risk_uniform = {\n",
    "    1: 0.0,\n",
    "    2: 0.125,\n",
    "    3: 0.25,\n",
    "    4: 0.375,\n",
    "    5: 0.50,\n",
    "    6: 0.375,\n",
    "    7: 0.25,\n",
    "    8: 0.125,\n",
    "    9: 0.0\n",
    "}\n",
    "\n",
    "risk_low = {\n",
    "    1: 0.000,\n",
    "    2: 0.243,\n",
    "    3: 0.447,\n",
    "    4: 0.385,\n",
    "    5: 0.250,\n",
    "    6: 0.146,\n",
    "    7: 0.071,\n",
    "    8: 0.023,\n",
    "    9: 0.000\n",
    "}\n",
    "\n",
    "risk_high = {\n",
    "    1: 0.000,\n",
    "    2: 0.023,\n",
    "    3: 0.071,\n",
    "    4: 0.146,\n",
    "    5: 0.250,\n",
    "    6: 0.385,\n",
    "    7: 0.447,\n",
    "    8: 0.243,\n",
    "    9: 0.000\n",
    "}\n",
    "\n",
    "# 2) Wrap them in one master dictionary keyed by distribution\n",
    "risk_map = {\n",
    "    'uniform': risk_uniform,\n",
    "    'low':     risk_low,\n",
    "    'high':    risk_high\n",
    "    # If you have a 'mix' condition, decide how to handle or skip it\n",
    "}\n",
    "\n",
    "# 3) For each DataFrame in your list, create a 'risk' column\n",
    "for df in dataframes:\n",
    "    df['risk'] = df.apply(\n",
    "        lambda row: risk_map.get(row['distribution'], {}).get(row['myCard'], np.nan),\n",
    "        axis=1\n",
    "    )\n",
    "    \n",
    "\n",
    "dataframes[1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6630c6ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_folder = 'data_risk_added'\n",
    "\n",
    "for file_name in os.listdir(folder_path):\n",
    "    if file_name.endswith('.xlsx'):\n",
    "        # Read the Excel file\n",
    "        file_path = os.path.join(folder_path, file_name)\n",
    "        df = pd.read_excel(file_path)\n",
    "        \n",
    "        # Compute the new 'risk' column\n",
    "        def compute_risk(row):\n",
    "            dist = row['distribution']\n",
    "            card = row['myCard']\n",
    "            return risk_map.get(dist, {}).get(card, np.nan)\n",
    "        \n",
    "        df['risk'] = df.apply(compute_risk, axis=1)\n",
    "\n",
    "        # (Optional) do any other modifications you need here...\n",
    "        \n",
    "        # Save the updated DataFrame with the same filename to data_risk_added\n",
    "        out_path = os.path.join(output_folder, file_name)\n",
    "        df.to_excel(out_path, index=False)\n",
    "\n",
    "print(\"All files processed and saved with 'risk' column in\", output_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6002cae4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
